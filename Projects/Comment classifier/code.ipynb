{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13lfzdo5vmdi1cm123te5uz2mqig1brz04</td>\n",
       "      <td>ferleck ferles</td>\n",
       "      <td>2013-11-27T21:39:24</td>\n",
       "      <td>Subscribe to my channel ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z12avveb4xqiirsix04chxviiljryduwxg0</td>\n",
       "      <td>BeBe Burkey</td>\n",
       "      <td>2013-11-28T16:30:13</td>\n",
       "      <td>and u should.d check my channel and tell me wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID           AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU        Julius NM   \n",
       "1          z13jhp0bxqncu512g22wvzkasxmvvzjaz04  ElNino Melendez   \n",
       "2          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw           GsMega   \n",
       "3          z13lfzdo5vmdi1cm123te5uz2mqig1brz04   ferleck ferles   \n",
       "4          z12avveb4xqiirsix04chxviiljryduwxg0      BeBe Burkey   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "2  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "3  2013-11-27T21:39:24                          Subscribe to my channel ﻿   \n",
       "4  2013-11-28T16:30:13  and u should.d check my channel and tell me wh...   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "# df = pd.read_csv('test.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nHere there is no direct connection between the comment id and the class label. becuase these comment ids are randomly generated.\\nwhich has no direct impact on class lable.\\nHere class lable is only dependet on the content of the comment.\\n\\nSO, I can use the NLP for this purpose.\\nHere I gonna use pretrained NLP model fot this porpose.\\nAnd by using this pretrained model, I can get the some parameteres which are very useful for to predict the class label.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Here there is no direct connection between the comment id and the class label. becuase these comment ids are randomly generated.\n",
    "which has no direct impact on class lable.\n",
    "Here class lable is only dependet on the content of the comment.\n",
    "\n",
    "SO, I can use the NLP for this purpose.\n",
    "Here I gonna use pretrained NLP model fot this porpose.\n",
    "And by using this pretrained model, I can get the some parameteres which are very useful for to predict the class label.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['AUTHOR', 'COMMENT_ID', 'DATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=df.CLASS\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    586\n",
       "0    571\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['CLASS'], axis=1)\n",
    "y = df['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df['CONTENT'],y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Initialize a TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "\n",
    "#DataFlair - Fit and transform train set, transform test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.22%\n",
      "Accuracy: 89.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       113\n",
      "           1       0.88      0.92      0.90       119\n",
      "\n",
      "    accuracy                           0.89       232\n",
      "   macro avg       0.89      0.89      0.89       232\n",
      "weighted avg       0.89      0.89      0.89       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Initialize a PassiveAggressiveClassifier\n",
    "\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "\n",
    "pac.fit(tfidf_train,y_train)\n",
    "\n",
    "#DataFlair - Predict on the test set and calculate accuracy\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "print(f'Accuracy: {round(roc*100,2)}%')\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 98,  15],\n",
       "       [ 10, 109]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Build confusion matrix\n",
    "confusion_matrix(y_test,y_pred, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(tfidf_train, y_train)\n",
    "y_prediction = clf.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.95%\n",
      "roc: 90.82%\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,y_prediction)\n",
    "roc = roc_auc_score(y_test, y_prediction)\n",
    "\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "print(f'roc: {round(roc*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_tfidf=tfidf_vectorizer.transform(test_df['CONTENT'])\n",
    "y_pred=clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisstion = pd.DataFrame()\n",
    "submisstion['ID'] = test_df['ID']\n",
    "submisstion['CLASS'] = y_pred\n",
    "submisstion.to_csv('ans1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nueral netowork model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = tfidf_train.shape[1]  # Number of features\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "ann_model = Sequential(layers=[\n",
    "    Dense(units=1024,activation='relu',input_shape=[input_dim]),\n",
    "    Dense(units=512,activation='tanh'),\n",
    "    Dense(1,activation='sigmoid')]\n",
    ")\n",
    "ann_model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 0.4507 - accuracy: 0.8086\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 0.0572 - accuracy: 0.9805\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0070 - accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 6.8208e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 5.0034e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 4.2584e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 3.3310e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 3.0852e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c867cccdc0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(tfidf_train.toarray(), y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = ann_model.predict(tfidf_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for x in y_pr:\n",
    "    if x >= 0.5:\n",
    "        f.append(1)\n",
    "    else:\n",
    "        f.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34459802508354187, 0.9094827771186829]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.evaluate(tfidf_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisstion = pd.DataFrame()\n",
    "submisstion['ID'] = test_df['ID']\n",
    "submisstion['CLASS'] = f\n",
    "submisstion.to_csv('ans1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 1024)              2622464   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,147,777\n",
      "Trainable params: 3,147,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ann_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified ann (colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input,GlobalMaxPool1D,Dropout\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords #corpus is collection of text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_size=500\n",
    "messages=x.copy()\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset Preprocessing\n",
    "ps =PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    print(\"Status: %s / %s\" %(i, len(messages)), end=\"\\r\")\n",
    "    review = re.sub('[^a-zA-Z]', ' ',messages['CONTENT'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(500,int(100),input_length=input_dim))\n",
    "model.add(LSTM(100, return_sequences=True,name='lstm_layer'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-tranined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "\n",
    "# Create a TransformerModel\n",
    "model = ClassificationModel('roberta', 'roberta-base')\n",
    "\n",
    "# Train the model\n",
    "model.train_model(df)\n",
    "\n",
    "# Evaluate the model\n",
    "# result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "999a47f3f740529c32b38bb2ebebf98f131bd6a8ea3815996aa6c35373f1dc20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
