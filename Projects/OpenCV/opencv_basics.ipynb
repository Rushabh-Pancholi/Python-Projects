{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "karnel = np.ones((2, 2), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('rushabh.jpeg')\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "# read the image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = cv2.VideoCapture()\n",
    "while True:\n",
    "    success, img = vd.read()\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "# this is how you can play a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" vd = cv2.VideoCapture(0)\\nvd.set(3, 640)\\nvd.set(4, 480)\\nvd.set(10, 100)\\n\\nwhile True:\\n    success, img = vd.read()\\n    cv2.imshow('image', img)\\n    if cv2.waitKey(1) & 0xFF == ord('q'):\\n        break \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### how to use webcam\n",
    "''' vd = cv2.VideoCapture(0)\n",
    "vd.set(3, 640) # set width\n",
    "vd.set(4, 480) # set height\n",
    "vd.set(10, 100) # set brightness\n",
    "\n",
    "while True:\n",
    "    success, img = vd.read()\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some basic operations with images\n",
    "img = cv2.imread('rushabh.jpeg')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_blur = cv2.GaussianBlur(img, (9, 9), 0)\n",
    "img_canny = cv2.Canny(img_blur, 100, 70)\n",
    "img_Dilation = cv2.dilate(img_canny, karnel, iterations=1)\n",
    "img_erroed = cv2.erode(img_Dilation,karnel,iterations=1)\n",
    "\n",
    "cv2.imshow('image',img_erroed)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# here in opencv we have same convwertion as cartesian but just y is in reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 750, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image resizing and cropping\n",
    "\n",
    "img1 = cv2.imread('rushabh.jpeg')\n",
    "print(img1.shape)\n",
    "\n",
    "img_resize = cv2.resize(img1,(500,550))\n",
    "img_cropp = img[0:500,100:700, 1:2] # height, width, color\n",
    "\n",
    "cv2.imshow('image', img_cropp)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create diffrent shapes on the image and text\n",
    "\n",
    "img_rand = np.ones((512, 512, 3), np.uint8)\n",
    "\n",
    "#img_rand[:] = 255,0,0 # blue this is the same as img_rand[:,:,0] = 255\n",
    "# img_rand[:] = 0,0,255 # red  here : represents all the pixels\n",
    "# img_rand[:] = 0,255,0 # green\n",
    "\n",
    "\n",
    "cv2.line(img_rand,(0,0),(img_rand.shape[1], img_rand.shape[0]),(155,100,0),1) # height, width\n",
    "cv2.rectangle(img_rand,(100,100),(200,200),(0,155,0),1) # put thickness as -1 for filled\n",
    "cv2.circle(img_rand,(300,300),100,(155,0,0),2)\n",
    "cv2.putText(img_rand, 'Rushabh', (200,100),cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (255,255,255), 1)\n",
    "\n",
    "cv2.imshow('image', img_rand)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'width, height = 800, 600\\nplts1 = np.float32([[0,0],[287,0],[0,580],[287,580]])\\nplts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\\nmatrix = cv2.getPerspectiveTransform(plts1,plts2)\\nimage = cv2.warpPerspective(img,matrix,(width,height))\\ncv2.imshow('image', image)\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cropping some part of the image and make it streaght \n",
    "# this is called as get prespective transform\n",
    "\n",
    "width, height = 800, 600\n",
    "plts1 = np.float32([[0,0],[287,0],[0,580],[287,580]])\n",
    "plts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrix = cv2.getPerspectiveTransform(plts1,plts2)\n",
    "image = cv2.warpPerspective(img,matrix,(width,height))\n",
    "cv2.imshow('image', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining the image \n",
    "image = cv2.imread('rushabh.jpeg')\n",
    "\n",
    "hrsta = np.hstack((image, image)) # horizontal join\n",
    "varsta = np.vstack((image, image)) # vertical join\n",
    "\n",
    "# here both image should be same channelled, weather it is colouer or grayscale\n",
    "\n",
    "cv2.imshow('image', hrsta)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# color detection in image\\ndef nothing(x):\\n    pass\\n\\n# find proper values for min and max and then you can extract the color\\ncv2.namedWindow('trackbar')\\ncv2.resizeWindow('trackbar', 600,600)\\ncv2.createTrackbar('Hue Min', 'trackbar', 13, 179, nothing)\\ncv2.createTrackbar('Hue Max', 'trackbar', 179, 179, nothing)\\ncv2.createTrackbar('sat Min', 'trackbar', 13, 255, nothing)\\ncv2.createTrackbar('sat Max', 'trackbar', 255, 255, nothing)\\ncv2.createTrackbar('val Min', 'trackbar', 0, 255, nothing)\\ncv2.createTrackbar('val Max', 'trackbar', 255, 255, nothing)\\n\\nwhile True:\\n\\n    img  = cv2.imread('rushabh.jpeg')\\n    imgHSV =  cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\\n\\n    h_min = cv2.getTrackbarPos('Hue Min', 'trackbar')\\n    h_max = cv2.getTrackbarPos('Hue Min', 'trackbar')\\n    sat_min = cv2.getTrackbarPos('sat Min', 'trackbar')\\n    sat_max = cv2.getTrackbarPos('sat Max', 'trackbar')\\n    val_min = cv2.getTrackbarPos('val Min', 'trackbar')\\n    val_max = cv2.getTrackbarPos('val Max', 'trackbar')\\n    \\n    lower = np.array([h_min, sat_min, val_min])\\n    higher = np.array([h_max, sat_max, val_max])\\n    print(h_min, h_max, sat_min, sat_max, val_min, val_max)\\n    mask = cv2.inRange(imgHSV, lower,higher)\\n    \\n    imgResult = cv2.bitwise_and(img, img, mask=mask)\\n    \\n    # cv2.imshow('image', imgHSV)\\n    # cv2.imshow('mask', mask)\\n    # cv2.imshow('result', imgResult)\\n    imgstack = stackImages(0.3,([img, imgHSV], [mask, imgResult]))\\n    cv2.imshow('image', imgstack)\\n    cv2.waitKey(1)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# color detection in image\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# find proper values for min and max and then you can extract the color\n",
    "cv2.namedWindow('trackbar')\n",
    "cv2.resizeWindow('trackbar', 600,600)\n",
    "cv2.createTrackbar('Hue Min', 'trackbar', 13, 179, nothing)\n",
    "cv2.createTrackbar('Hue Max', 'trackbar', 179, 179, nothing)\n",
    "cv2.createTrackbar('sat Min', 'trackbar', 13, 255, nothing)\n",
    "cv2.createTrackbar('sat Max', 'trackbar', 255, 255, nothing)\n",
    "cv2.createTrackbar('val Min', 'trackbar', 0, 255, nothing)\n",
    "cv2.createTrackbar('val Max', 'trackbar', 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "\n",
    "    img  = cv2.imread('rushabh.jpeg')\n",
    "    imgHSV =  cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h_min = cv2.getTrackbarPos('Hue Min', 'trackbar')\n",
    "    h_max = cv2.getTrackbarPos('Hue Min', 'trackbar')\n",
    "    sat_min = cv2.getTrackbarPos('sat Min', 'trackbar')\n",
    "    sat_max = cv2.getTrackbarPos('sat Max', 'trackbar')\n",
    "    val_min = cv2.getTrackbarPos('val Min', 'trackbar')\n",
    "    val_max = cv2.getTrackbarPos('val Max', 'trackbar')\n",
    "    \n",
    "    lower = np.array([h_min, sat_min, val_min])\n",
    "    higher = np.array([h_max, sat_max, val_max])\n",
    "    print(h_min, h_max, sat_min, sat_max, val_min, val_max)\n",
    "    mask = cv2.inRange(imgHSV, lower,higher)\n",
    "    \n",
    "    imgResult = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # cv2.imshow('image', imgHSV)\n",
    "    # cv2.imshow('mask', mask)\n",
    "    # cv2.imshow('result', imgResult)\n",
    "    imgstack = stackImages(0.3,([img, imgHSV], [mask, imgResult]))\n",
    "    cv2.imshow('image', imgstack)\n",
    "    cv2.waitKey(1) \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def getContours(img):\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cr in contours :\n",
    "        area = cv2.contourArea(cr)\n",
    "        # print(area)\n",
    "        if area > 500 :\n",
    "            cv2.drawContours(imgcopy, cr, -1, (255,0,0), 3)\n",
    "            perimeter = cv2.arcLength(cr, True)                 # to get the perimeter\n",
    "            approx = cv2.approxPolyDP(cr, 0.02*perimeter, True) # approxPolyDP is used to approximate the polygon\n",
    "            corner = len(approx)\n",
    "            x,y,w,h = cv2.boundingRect(approx)                  # x,y is the top left corner and w,h is the width and height \n",
    "            \n",
    "            cv2.rectangle(imgcopy, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            \n",
    "            if corner == 3: objectType = 'tri'\n",
    "            elif corner == 4 : \n",
    "                asspect = w/h\n",
    "                if asspect > 1.1 : objectType = 'rect'\n",
    "                else : objectType = 'sqr'\n",
    "            elif corner > 4 : objectType = 'cir'\n",
    "            else : objectType = 'None'\n",
    "            \n",
    "            cv2.putText(imgcopy, objectType, (x-10,y-10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.2, (0,0,0), 2)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counture and shape detection\n",
    "\n",
    "image = cv2.imread('shapes.png')\n",
    "img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#img_blur = cv2.GaussianBlur(img_gray, (7,7), 1)\n",
    "img_canny = cv2.Canny(img_gray, 50, 50)\n",
    "img_Dilation = cv2.dilate(img_canny, karnel, iterations=1)\n",
    "imgcopy = image.copy()\n",
    "imgblack = np.zeros_like(image)\n",
    "\n",
    "getContours(img_Dilation)\n",
    "imagestak = stackImages(0.7, ([image, imgcopy]))\n",
    "cv2.imshow('image', imagestak)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to detect face in image\n",
    "'''facecas = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # download the xml file\n",
    "img = cv2.imread('rushabh.jpeg')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = facecas.detectMultiScale(img_gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    \n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "999a47f3f740529c32b38bb2ebebf98f131bd6a8ea3815996aa6c35373f1dc20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
